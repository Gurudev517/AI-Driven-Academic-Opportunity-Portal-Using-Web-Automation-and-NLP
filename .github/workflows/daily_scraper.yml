name: Daily Internship Scraper

on:
  schedule:
    - cron: '0 0 * * *'  # Runs every day at Midnight UTC
  workflow_dispatch:      # Allows you to run it manually to test

jobs:
  scrape_and_update:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write  # Permission to update the database file

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Libraries
        # We look inside the 'backend' folder for requirements.txt
        run: |
          pip install -r requirements.txt
        working-directory: ./backend

      - name: Run Scraper
        # We run the script inside the 'backend' folder
        run: python scraper.py
        working-directory: ./backend

      - name: Commit and Push Database
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ðŸ¤– Auto-Update: Refreshed Database"
          # Look for the DB inside backend. 
          # Note: If your scraper creates 'internships.db', change the name below!
          file_pattern: "backend/*.db"